---
title: "Assignment 2 Andrew Pierson"
author: "Andrew Pierson"
date: "11/12/2018"
output: html_document
---
#Question 1

##Setup Data and Packages
```{r Q1 Setup}
#Enable knit to csv
knitr::opts_chunk$set(echo = TRUE)

#Read in packages that have already been installed
library(forecast)
library(expsmooth)
library(seasonal)
library(fpp2)
library(ggplot2)
```

##Part A
Experiment with the various options in the holt() function to see how much the forecasts change with damped or exponential trend. Try changing the parameter values for alpha and beta to see how they affect the forecasts. You should do at least 5 forecasts. 

Here I changed the forecast parameters to use the default settings and also have varying alpha and beta parameter settings. The second and third fits both have the same alpha value, this is to give us an indication to how our beta parameter is affecting the forecast. The third and fourth fits have a constant beta value to give a better understanding of how the alpha parameter changes the forecast.

```{r Q1 Part A}
#Forecast the specified window of data
fc1 <- holt(eggs, h=15)
fc2 <- holt(eggs,  alpha=0.9, beta=0.1, initial="simple", h = 15)
fc3 <- holt(eggs,  alpha=0.9, beta=0.6, initial="simple", h = 15)
fc4 <- holt(eggs,  alpha=0.5, beta=0.8, initial="simple", h = 15)
fc5 <- holt(eggs,  alpha=0.1, beta=0.8, initial="simple", h = 15)

#Plot the forecasts
autoplot(eggs) + 
  autolayer(fc1, series = "Holt's Method", PI = FALSE, color = 'red') + 
  autolayer(fc2, series = "Holt's Method", PI = FALSE, color = 'blue') + 
  autolayer(fc3, series = "Holt's Method", PI = FALSE, color = 'green') + 
  autolayer(fc4, series = "Holt's Method", PI = FALSE, color = 'yellow') + 
  autolayer(fc5, series = "Holt's Method", PI = FALSE, color = 'purple') +   
  ggtitle("Forecast from Holt's Linear Method") + xlab("Year") + ylab("Thousands of cars") + 
  guides(color = guide_legend(title = "Forecast"))
```

##Part B
Try to develop an intuition of what each parameter and argument is doing to the forecasts. [Hint: use h=100 when calling holt() so you can clearly see the differences between the various options when plotting the forecasts.] How would you explain that intuition? 

The intuition that I would explain when changing the parameters for alpha and beta would be different. While changing the parameter of alpha, I would describe an increase in the parameter value as having an effect where the forecasted series' level is increasing. For the beta parameter, I would describe changes to this parameter as having an effect on the trend of the forecast. 

```{r Q1 Part B}
#Forecast the specified window of data
fc1_h100 <- holt(eggs, h=100)
fc2_h100 <- holt(eggs,  alpha=0.9, beta=0.1, initial="simple", h = 100)
fc3_h100 <- holt(eggs,  alpha=0.9, beta=0.6, initial="simple", h = 100)
fc4_h100 <- holt(eggs,  alpha=0.5, beta=0.8, initial="simple", h = 100)
fc5_h100 <- holt(eggs,  alpha=0.1, beta=0.8, initial="simple", h = 100)

#Plot the forecasts
autoplot(eggs) + 
  autolayer(fc1, series = "Holt's Method", PI = FALSE, color = 'red') + 
  autolayer(fc2, series = "Holt's Method", PI = FALSE, color = 'blue') + 
  autolayer(fc3, series = "Holt's Method", PI = FALSE, color = 'green') + 
  autolayer(fc4, series = "Holt's Method", PI = FALSE, color = 'yellow') + 
  autolayer(fc5, series = "Holt's Method", PI = FALSE, color = 'purple') +   
  ggtitle("Forecast from Holt's Linear Method") + xlab("Year") + ylab("Thousands of cars") + 
  guides(color = guide_legend(title = "Forecast"))
```

##Part C
Which model gives the best RMSE? 

The model with the lowest RMSE is the first model, using the automatically adjusted alpha and beta parameters. Respectively they are 0.8124 and 1e-04.

```{r Q1 Part C}
#RMSE of the 5 different holt models
summary(fc1)
summary(fc2)
summary(fc3)
summary(fc4)
summary(fc5)
```

#Question 2

##Setup Data and Packages
```{r Q2 Setup}
#Read in packages that have already been installed
library(forecast)
library(expsmooth)
library(seasonal)
library(ggplot2)
library(fpp2)
```

##Part A
Plot your data and describe the main features of the series.

The ukcars dataset ranges from 1977 to 2005 and contains observations of the number of cars in thousands. The plot of data spans 112 periods, each lasting a quarter of a year. This plot appears to be seasonal and trending throughout certain ranges of years. One example of a trend from this dataset is the positive trend from around 1985 to 2000, which has quarterly seasonality.

```{r Q2 Part A}
#Plot the ukcars dataset
autoplot(ukcars) + 
  ggtitle("UK Cars") + xlab("Year") + ylab("Thousands of cars")
```

##Part B
Decompose the series using STL and obtain the seasonally adjusted data.

The first chart below is the ukcars dataset decomposed to compare the data to its seasonality, trend, and autocorrelation plots. This allows us to see the trend, which seems to start out decreasing and increase for about 20 years before seeing a sharp decrease. The seasonality also appears to be constant. The seasonally adjusted data seems to remove the constant seasonality from most of the data.

```{r Q2 Part B}
library(zoo)
#Convert to zoo object
ukcarsdata <- as.zoo(ukcars)

#Decomposed data lists 8 seasonally adjusted data points
stl <- stl(ukcarsdata, s.window="periodic")
plot(stl)


#Obtain seasonally adjusted data using x11
sad <- seasadj(stl)
plot(sad)
#seasonal::series(sad, "forecast.forecasts")
```

##Part C
Forecast the next two years of the series using Holt's linear trend method applied to the seasonally adjusted data

In this part I printed a summary of the fit that I was using and the forecasted data over 2 years which equated to eight periods in the holt forecasting function. The forecasted data indicates a trend that is increasing linearly over the next 2 years. 

```{r Q2 Part C}
#Use Holt's method to create a forecast
fc <- holt(sad, h=8)

#Run the summary of the forecasting method
summary(fc)

#Plot Holt's linear method forecast
autoplot(sad) + 
  autolayer(fc, series = "Holt's Method", PI = FALSE) + 
  ggtitle("Forecast from Holt's Linear Method") + xlab("Year") + ylab("Thousands of cars") + 
  guides(color = guide_legend(title = "Forecast"))
```

##Part D
What are the parameters of the method? What do they tell you about how quickly the slope and level are changing over time?
```{r Q2 Part D}
print("The parameters of the holt's method function that I used were sad and h = 8. These parameters indicate that the data I am using has been seasonally adjusted and that I am forecasting eight periods. The damped parameter has been automatically set to false and the initial set to simple. It has also indicated that it is not using an exponential trend.")
```

##Part E
Reseasonalize the forecasts using the following code where decomp is the output from stl() and fit is the output from holt()

```{r Q2 Part E}
#Decompose the data using the stl() function
decomp <- stl(ukcars, s.window="periodic")

#Fit the data using Holt's linear method
fit <- holt(sad, h = 8)

#Define the data from the previous period
lastyear <- rep(decomp$time.series[110:113,"seasonal"],2) 
fc <- fit$mean + lastyear

#Plot the forecast using Holt's method with seasonalized data
autoplot(ukcars) + 
  autolayer(fc, series = "Holt's Method", PI = FALSE, color = 'green') + 
  ggtitle("Forecast from Holt's Linear Method") + xlab("Year") + ylab("Thousands of cars") + 
  guides(color = guide_legend(title = "Forecast"))
```

##Part F
Do the re-seasonalized forecasts look reasonable? Why or why not? 
```{r Q2 Part F}
print('The re-seasonalized forecasts look reasonable from a standpoint of having a similar variation across periods. However, there does not appear to be any trend to the forecasted seasonality.')
```

##Part G
Use ets() to choose a seasonal model for the data.  How would you explain the results? 

After applying the ets function to the ukcars data I would recommend using a ETS(A, N, A) model. This result comes from the ets parameter model = "ZZZ" which allows the model to choose the framework of Hyndman where A denotes additive, M denotes multiplicative, and N denotes none. Additionally, the place of the framework identifies (error type, trend type, season type). 

```{r Q2 Part G}
#Use ets() function to choose a seasonal model
ets(ukcars, model = "ZZZ")
```

##Part H
Apply both an X11 and a SEATS model using a two year horizon. 

```{r Q2 Part H}
#Load seasonal package from library
library(seasonal)
library(seasonalview)
library(shiny)
ukcars <- ukcars
#Define seas function for X-11ARIMA
x11 <- seas(ukcars,
          x11 = "",
          transform.function = "auto",
          forecast.maxlead = 12,
          forecast.probability = 0.9,
          forecast.exclude = 4)

#Print the x11 forecasted data
a <- seasonal::series(x11, "forecast.forecasts")
print("X11 Forecast:")
print(a)
#Define seas function for SEATS
seats <- seas(ukcars,
          transform.function = "auto",
          forecast.maxlead = 12,
          forecast.probability = 0.9,
          forecast.exclude = 4)

#Print the SEATS forecasted data
b <- seasonal::series(seats, "forecast.forecasts")
print("SEATS Forecast:")
print(b)
```

##Part I
Compare the RMSE of the fitted model with the RMSE of the model above. Which gives the better in-sample fits?  How would you explain that? 

The RMSE of the fitted model, which is the holt linear trend method applied to seasonally adjusted data and forecasted over an eight period horizon gives the optimal value. The X11 model and SEATS model both give an output of 26.52 for their RMSE values. I would explain this by saying that there wasn't any variation between methods.

```{r Q2 Part I}
#RMSE of the X11 series model
print("X11 RMSE:")
sqrt(mean((x11$series$rsd)**2))

#RMSE of the fitted model
print("SEATS RMSE:")
sqrt(mean((seats$series$rsd)**2))

#RMSE of the fitted model
print("FIT RMSE:")
summary(fit)
```

##Part J
Now compare the forecasts from the above approaches? Which seems most reasonable? Why? 

The forecast from the x11 approach seems the most reasonable because it appears to have a consistent seasonality.

```{r Q2 Part J}
#Plot the data
autoplot(ukcars) + 
  autolayer(a, series = "Holt's Method", PI = FALSE, color = 'green') + 
  ggtitle("Forecast from Holt's Linear Method") + xlab("Year") + ylab("Thousands of cars") + 
  guides(color = guide_legend(title = "Forecast"))

#Plot the data
autoplot(ukcars) + 
  autolayer(b, series = "Holt's Method", PI = FALSE, color = 'green') + 
  ggtitle("Forecast from Holt's Linear Method") + xlab("Year") + ylab("Thousands of cars") + 
  guides(color = guide_legend(title = "Forecast"))

#Plot the data
autoplot(ukcars) + 
  autolayer(fit, series = "Holt's Method", PI = FALSE, color = 'green') + 
  ggtitle("Forecast from Holt's Linear Method") + xlab("Year") + ylab("Thousands of cars") + 
  guides(color = guide_legend(title = "Forecast"))
```


#Question 3

##Setup Data and Packages
```{r Q3 Setup}
#Read in packages that have already been installed
library(expsmooth)
library(forecast)
library(fpp2)
```

##Part A
Make a time plot of your data and describe the main features of the series. 

This data is a time series from 1985 to 2005 which seems to have an increasing seasonality over periods and an increasing trend. There also appears to be an outlier that creates a large decrease in the time series around 1989 and 2003.

```{r Q3 Part A}
#Plot the data
autoplot(visitors) + 
  xlab("Year") + ylab("Visitor nights (millions") + 
  ggtitle("International visitors nights in Australia")
```

##Part B
Forecast the next two years using Holt-Winters' multiplicative method. Why is multiplicative seasonality necessary here?  

The multiplicative seasonality is necessary when forecasting using the Holt-Winters' method to ensure that the seasonality is increasing. 

```{r Q3 Part B}
#Fit the forecast using Holt-Winters' multiplicative method
hwm <- hw(visitors, seasonal = "multiplicative")
#Plot the Holt-Winters' forecast
autoplot(visitors) + 
  autolayer(hwm, series = "HW multiplicative forecasts", PI = FALSE) + 
  xlab("Year") + ylab("Visitor nights (millions") + 
  ggtitle("International visitors nights in Australia")
```

##Part C
Experiment with making the trend exponential and/or damped, investigating at least two alternatives. Why did you choose the options you did?  

I chose the multiplicative seasonal parameter and damped parameter set to true to see if the dampening effect was similar to the trend of the original time series. The other trenf that I chose was to see a Holt-Winters' model with an additive parameter. I was interested to see what would happen if the seasonality did not keep increasing as it had in the original time series.

```{r Q3 Part C}
#Holt-Winters multiplicative method with damped trend
hwmd <- hw(visitors, damped = TRUE, seasonal = "multiplicative")

#Holt-Winters multiplicative method with exponential trend
hwme <- hw(visitors, seasonal = "additive")

#Plot the Damped Holt-Winters' forecast
autoplot(visitors) + 
  autolayer(hwmd, series = "HW multiplicative damped forecasts", PI = FALSE) + 
  xlab("Year") + ylab("Visitor nights (millions") + 
  ggtitle("International visitors nights in Australia")

#Plot the Additive Holt-Winters' forecast
autoplot(visitors) + 
  autolayer(hwme, series = "HW additive forecasts", PI = FALSE) + 
  xlab("Year") + ylab("Visitor nights (millions") + 
  ggtitle("International visitors nights in Australia")
```

##Part D
Compare the RMSE of the one-step forecasts from the various methods. Which do you prefer?  Why?  

The Holt-Winters' default method, Holt-Winters' Damped Multiplicative Method, and Holt-Winters' Additive method returned respective RMSE values of 14.66, 14.41, and 18.02. Multiplicative Damped Holt-Winters' Method returns the smallest RMSE value, therefore I would choose this method. 

```{r Q3 Part D}
#RMSE of Holt-Winters' Method
summary(hwm)

#RMSE of Holt-Winters' Damped Method
summary(hwmd)

#RMSE of Holt-Winters' Additive Method
summary(hwme)
```

##Part E
Now use the ets() function to select a model automatically. Does it choose the same model you did? How would you explain that? 

The model chose the same as the one that I suggested had the best RMSE from the above Holt-Winters' models. I would explain that my model also chose multiplicative error type, an additive trend, and a multiplicative seasonality. I would then explain the parameters of the Holt-Winters' method that I used to generate the forecast. 
```{r Q3 Part E}
#Use ets() function to select a model automatically
visitors_ets <- ets(visitors )
print(visitors_ets)

#Plot the decomposed data 
plot(visitors_ets)

#Plot forecast of model
autoplot(forecast(visitors_ets, h = 24), ylab = "Visitor nights (in millions)")
```


#Question 4

##Setup Data and Packages
```{r Q4 Setup}
#Enable knit to csv
knitr::opts_chunk$set(echo = TRUE)

#Set appropriate working directory
getwd()
#setwd("C:/Users/Andrew/Desktop/Assignment 2")

#Read in packages that have already been installed
library(expsmooth)
library(forecast)
library(fpp2)
library(zoo)
library(xts)
library(ggplot2)
```

##Part A
Plot the raw time series and comment. 

This time serious plot of the log of alcohol demand over time ranges from April 1870 to December 1938. The time series data appears to be stochastic, it does not have a strong trend and the patterns in a periodical view do not have any pattern that I would describe as seasonal. 

```{r Q4 Part A}
#Import the data csv. stringsasFactors ensures the numeric values can be treated as decimals later
df <- read.csv("/Users/AndrewPierson/Desktop/Assignment 2/alcohol-demand-log-spirits-consu.csv", stringsAsFactors = FALSE)

#Look at the first rows of the data frame
print(head(df))
print(tail(df))

#Change column names to something easier for following code
colnames(df) <- c("Month", "logconsump")

#The last two rows should not be included in the file, they are informational and not true data
df <- df[-c(208, 209),]

#Confirm the last two rows are gone
print(tail(df))

#Convert the date column to a date object and sort from oldest to newest
df$Month = as.yearmon(df$Month)
df=df[order(df$Month),]

#Convert the log consumption into a numerical object
df$logconsump <- as.numeric(df$logconsump)

#Subset the desired data to exclude the null column
df <- subset(df, select = c("Month", "logconsump"))

#Convert the data frame into a time series object
alc <- read.zoo(df, FUN = as.yearmon)

#Plot the raw time series data
autoplot.zoo(alc, main = "Log Alcohol Consumption per Head UK 1870-1938") + xlab("Month and Year") + ylab("Log Alcohol Consumption")

```

##Part B
Run a decompose function. Describe the components you see.  

From the decomposed time series object there appears to be a weak positive trend. I still do not see any evidence of seasonality.

```{r Q4 Part B}
#Decompose the series using stl() function
alc_decomp <- stl(alc, s.window = 3)

#Plot the decomposed data
autoplot(alc_decomp)
```

##Part C
Test for normality using the Jaques-Berra test as well as a qqlot.  

```{r Q4 Part C}
#Read in packages that have already been installed
library(fBasics)

#Jaques-Berra test
normalTest(alc, method = c("jb"))

#QQ Normality plot with regression line
qqnorm(alc)
qqline(alc, col = 2)
```

##Part D
If not normal (ND)- transform using a Box-Cox (see the code in Week 3-4 code). 

Transformation parameter increased showed better results, more points appear to have a closer fit to the mean normal distribution regression line.

```{r Q4 Part D}
#QQ Normality plot with regression line for Box-Cox transformed data
qqnorm(BoxCox(alc, 4))
qqline(BoxCox(alc, 4), col = 2)
```

##Part E
Run and check the ACF (and comment) lag structure. 

This suggests that the lag is decreasing linearly as the lag number increases. The more periods out that are used to train the forecast, the less of an effect the data points will have in the data produced from the forecast.

```{r Q4 Part E}
#Run acf() function to display a visual of the lag structure
acf(alc)
```

##Part F
Run the LJUNG-BOX test for auto-correlation and 3 lags and 6 lags. Comment.

Test to determine if the autocorrelation shows significant relationships between observations. The X-squared value is twice as large when the lag is doubled. The degrees of freedom is the same number as the number of lags indicated by the function.

```{r Q4 Part F}
#LJUNG-BOX test with 3 lags 
Box.test(alc, lag = 3, type = "Ljung")

#LJUNG-BOX test with 6 lags 
Box.test(alc, lag = 6, type = "Ljung")
```
