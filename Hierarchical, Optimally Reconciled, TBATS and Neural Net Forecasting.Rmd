---
title: "Final Project"
author: "Andrew Pierson"
date: "December 10, 2018"
output: html_document
---

```{r setup, warning = FALSE, message = FALSE, tidy = TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(fpp2)
library(ggplot2)
#library(tidyverse)
library(forecast)
library(openxlsx)
library(readxl)
library(hts)
```

# Chapter 10

## Problem 2: 
### Generate 8-step-ahead bottom-up forecasts using ARIMA models for the visnights Australian domestic tourism data. Plot the coherent forecasts by level and comment on their nature. Are you satisfied with these forecasts?

```{r Chapter 10 Problem 2, warning = FALSE, message = FALSE, tidy = TRUE}
#Define the hierarchical time series
tourism.hts <- hts(visnights, characters = c(3, 5))

#Plot the hierarchical time series object
tourism.hts %>% aggts(levels = 0:1) %>% autoplot(facet = TRUE) + xlab("Year") + ylab("Millions") + ggtitle("Visitor Nights")

#Forecast ARIMA model
fc_visnights_arima <- forecast(tourism.hts, h = 8, method = "bu", fmethod = "arima")

#Plot the coherent forecasts by level
plot(fc_visnights_arima, levels = 0:1, color_lab = TRUE) 
title(main = "Total Visitor Nights in Australia
      ")
```

## Problem 3: 
### Model the aggregate series for the Australian domestic tourism data visnights using an ARIMA model. Comment on the model. Generate 8-step-ahead forecasts from the ARIMA model and compare these with the bottom-up forecasts generated in problem 2 for the aggregate level.

```{r Chapter 10 Problem 3, warning = FALSE, message = FALSE, tidy = TRUE}
#Forecast ARIMA model
fc_visnights_arima <- forecast(tourism.hts, h = 8, method = "bu", fmethod = "arima")

#Plot the coherent forecasts by level
plot(fc_visnights_arima, levels = 0) 
title(main = "Total Visitor Nights in Australia")

#Plot the coherent forecasts by level
plot(fc_visnights_arima, levels = 1) 
title(main = "Total Visitor Nights in Australia by State Group")

#Plot the coherent forecasts by level
plot(fc_visnights_arima, levels = 2) 
title(main = "Total Visitor Nights in Australia by State Zone")
```

## Problem 4: 
### Generate 8-step-ahead optimally reconciled coherent forecasts using ARIMA base forecasts for the visnights Australian  domestic tourism data. Plot the coherent forecasts by level and comment on their nature. How and why are these different to the bottom-up forecasts generated in problem 2 above?

```{r Chapter 10 Problem 4, warning = FALSE, message = FALSE, tidy = TRUE}
str(visnights)
str(smatrix(tourism.hts))

#Produce the optimally reconciled forecast
fc_visnights_arima_opt <- tourism.hts %>% forecast(h = 8, method = "comb", weights = "mint", covariance = "sam", fmethod = "arima")

#Plot the optimally reconciled and bottom-up forecasts 
plot(fc_visnights_arima_opt, levels = 0, col = "Blue")
par(new = TRUE, xpd = TRUE)
plot(fc_visnights_arima, levels = 0, col = "Green")
title(main = "Total Visitor Nights in Australia")
legend("bottomright", legend = c("Optimal", "Bottom-Up"), title = "Coherent Forecast", col = c("Blue", "Green"), lty = c(1, 1), bty = "n", cex = 0.5)

#Plot the optimally reconciled forecast level 1
plot(fc_visnights_arima_opt, levels = 1, color_lab = TRUE)
title(main = "Optimally Reconciled Forecasts of Total Visitor Nights in Australia by State Group")
#Plot the ARIMA forecast level 1
plot(fc_visnights_arima, levels = 1, color_lab = TRUE)
title(main = "ARIMA Forecasts of Total Visitor Nights in Australia by State Group")

#Plot the optimally reconciled forecast level 2
plot(fc_visnights_arima_opt, levels = 2, color_lab = TRUE)
title(main = "Optimally Reconciled Forecasts of Total Visitor Nights in Australia by State Zone")
#Plot the ARIMA forecast level 2
plot(fc_visnights_arima, levels = 2, color_lab = TRUE)
title(main = "ARIMA Forecasts of Total Visitor Nights in Australia by State Zone")

```

## Problem 5: 
### Using the last two years of the visnights Australian domestic tourism data as a test set, generate bottom-up, top-down, and optimally reconciled forecasts for this period and compare their accuracy.

```{r Chapter 10 Problem 5, warning = FALSE, message = FALSE, tidy = TRUE}
visnights %>% head()

#Define the train set
tourism.hts.train <- window(tourism.hts, end = c(2014, 4))
#Define the test set
tourism.hts.test <- window(visnights, start = 2015)

#Produce the optimally reconciled forecast
fc_visnights_test_arima_opt <- forecast(tourism.hts.train, h = 8, method = "comb", weights = "wls", fmethod = "arima")
#Produce the bottom-up forecast
fc_visnights_test_arima_bu <- forecast(tourism.hts.train, h = 8, method = "comb", weights = "wls", fmethod = "arima")
#Produce the top-down forecast

#Plot the optimally reconciled and bottom-up forecasts 
plot(fc_visnights_test_arima_opt, levels = 0, col = "Blue")
par(new = TRUE, xpd = TRUE)
plot(fc_visnights_test_arima_bu, col = "Green")
title(main = "Total Visitor Nights in Australia")
legend("bottomright", legend = c("Optimal", "Bottom-Up"), title = "Coherent Forecast", col = c("Blue", "Green"), lty = c(1, 1), bty = "n", cex = 0.5)
```

# Chapter 11

## Problem 1: Use the tbats() function to model your retail time series.

### Part A: Check the residuals and produce forecasts.

```{r Chapter 11 Problem 1 Part A, warning = FALSE, message = FALSE, tidy = TRUE}
#Change the working directory to the location of the dataset
getwd()
setwd('E:/Rockhurst University/FS18/B Term/BIA 6315 Time Series and Forecasting/Final Project')

#Load in the dataset 
retail <- read_excel("retail.xlsx", sheet = 1, skip = 1)
#Define the time series data and format periods
retail.ts <- ts(retail[,"A3349873A"], frequency=12, start=c(1982,4))
#Plot the time series with appropriate axis and title labels
autoplot(retail.ts) + xlab('Year') + ylab('Turnover') + ggtitle('Retail Turnover in New South Wales')

#Apply the TBATS function to the retail time series
retail.ts %>% tbats() %>% forecast() %>% autoplot() + xlab("") + ylab("Year") + ggtitle("Forecast of Retail Turnover in New South Wales")

#Check the residuals of the model
retail.ts %>% tbats() %>% checkresiduals()
```

### Part B: Does this completely automated approach work for these data?

The completely automated approach to forecasting the data appears to produce a close predictions. Upon inspection of the residuals we see the error isn't completely white noise and observe several significant spikes in autocorrelation. I think this model could be improved with another differencing.

```{r Chapter 11 Problem 1 Part B, warning = FALSE, message = FALSE, tidy = TRUE}
```

### Part C: Have you saved any degrees of freedom by using Fourier terms rather than seasonal differencing?

We appear to have saved 9 degrees of freedom.

```{r Chapter 11 Problem 1 Part B, warning = FALSE, message = FALSE, tidy = TRUE}
retail.ts %>% tbats()
```

## Problem 2: Consider the weekly data on US finished motor gasoline products supplied (millions of barrels per day) (series: gasoline)

### Part A: Fit a TBATS model to these data.

The TBATS model that was fitted to the gasoline time series produced a TBATS(1, {0,0}, -, {<52.18,12>}) variation of the model. The model also has an AIC value of 5882.748. 

```{r Chapter 11 Problem 2 Part A, warning = FALSE, message = FALSE, tidy = TRUE}
#Fit tbats model to the time series
gasonline.tbats <- gasoline %>% tbats()
gasonline.tbats
```

### Part B: Check the residuals and produce forecasts.

The residuals do not appear to be similar to white noise and there are many significant spikes in the autocorrelation plot. The forecast produced from the model does not appear to have a great fit. 

```{r Chapter 11 Problem 2 Part B, warning = FALSE, message = FALSE, tidy = TRUE}
#Check the residuals on the plot
gasonline.tbats %>% checkresiduals()
#Forecast the fitted model and plot
gasonline.tbats %>% forecast() %>% autoplot()
```

### Part C: Could you model these data using any of the other methods we have considered in this book?

These data could be modeled using a dynamic regression, specifically a harmonic regression model would deal with the trends in the data. Also, the ARIMA model would be able to minimize the residuals well. Either of these methods would work well for this time series.

```{r Chapter 11 Problem 2 Part C, warning = FALSE, message = FALSE, tidy = TRUE}
```

### Part D: Perform a bagging and bootstrapping on the gasoline dataset.

```{r Chapter 11 Problem 2 Part D, warning = FALSE, message = FALSE, tidy = TRUE}
#Bootstrap the values of the gasoline dataset
bootseries <- bld.mbb.bootstrap(gasoline, 10) %>% as.data.frame() %>% ts(start = 1991.1, frequency = 52.1785714285714)

#Plot the original series and the bootstrapped series
autoplot(gasoline) + autolayer(bootseries, colour = TRUE) + autolayer(gasoline, colour = FALSE) + ylab("Millions of Gasoline Barrels Per Day") + guides(colour = "none") + ggtitle("Bootstrap of US Finished Motor Gasoline Products Supplied")  

#Bootstrap the values of the gasoline dataset
sim <- bld.mbb.bootstrap(gasoline, 10) %>% as.data.frame() %>% ts(start = 1991.1, frequency = 52.1785714285714)

#Forecast the simulated series
fc <- purrr::map(as.list(sim), function(x){forecast(ets(x))[["mean"]]}) %>% as.data.frame() %>% ts(start = 1991.1, frequency = 52.1785714285714)

#Plot the bagged ets forecast
etsfc <- gasoline %>% ets() %>% forecast(h = 50) 
baggedfc <- gasoline %>% baggedETS() %>% forecast(h = 50)

#Plot the original series and the bootstrapped series forecasts
autoplot(gasoline) + autolayer(baggedfc, series = "BaggedETS", PI = FALSE) + autolayer(etsfc, series = "ETS", PI = FALSE) + ylab("Millions of Gasoline Barrels Per Day") + guides(colour = guide_legend(title = "Forecasts")) + ggtitle("Bagged ETS Bootstrap Forecast of US Finished Motor Gasoline Products Supply")
```

## Problem 3: Experiment with using nnetr() on your retail data and other data we have considered in previous chapters.

```{r Chapter 11 Problem 3, warning = FALSE, message = FALSE, tidy = TRUE}
#Forecast the retail demand using nnetr()
retail.ts %>% nnetar() %>% forecast() %>% autoplot() + xlab("Year") + ylab("Turnover") + ggtitle("Neural Net Forecast of Retail Turnover in New South Wales")

#Forecast the wmurders time series using nnetr()
wmurders %>% nnetar() %>% forecast() %>% autoplot() + xlab("Year") + ylab("Women Murdered (per 100,000 standard population)") + ggtitle("Neural Net Forecast of Number of Women Murdered Each Year")

#Forecast the austourists time series using nnetar()
austourists %>% nnetar() %>% forecast() %>% autoplot() + xlab("Year") + ylab("Number of International Tourists") + ggtitle("Neural Net Forecast of Quarterly Number of International Tourists to Australia From 1999 to 2010")
```

